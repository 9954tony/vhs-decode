FANN_FLO_2.1
num_layers=3
learning_rate=0.010000
connection_rate=0.500000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999999999999977796e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 13 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (7, 0, 5.00000000000000000000e-01) (7, 0, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(12, -2.07962368599420743820e-01) (4, 2.59200770954948112035e+00) (6, -1.11637942862854622206e+01) (8, -5.43537429354389090008e+00) (5, 7.18052471803769343239e+00) (3, 3.54697777651572865310e+00) (7, -6.11368886104490527611e-02) (12, 3.64606356617751481419e-01) (1, 3.62948813502568357059e-01) (2, -7.17523129946777471488e-01) (10, -7.04929774662343411329e-01) (5, 8.54915160070099378053e-02) (8, 3.52919425974161982129e-01) (4, -6.69879380473484720149e-01) (12, -5.31981498537784425196e-01) (3, 7.48253154274575449367e-02) (5, 4.32712250339560344781e-01) (8, -6.60330054071625260903e-01) (9, -4.70010269024165525109e-02) (6, -1.75890820139731629546e+00) (1, -4.21169371326475416861e-01) (12, 2.45536252768543017400e-01) (0, 1.95815123074914138046e-01) (1, 2.46847344955285596946e-01) (11, 7.06385191974367044471e-03) (6, 1.70868184129370714874e-01) (9, 1.76684404785963755646e-01) (3, 4.95401120423857241337e-02) (12, -3.21386176710326276762e+00) (9, -7.86978891195183272167e-01) (8, -1.13663613163045251753e+00) (7, -1.56358888683647179185e+00) (1, -1.19179854670478022061e-01) (6, -6.92643655361945165261e-01) (3, -4.87203781097272692335e-01) (12, -4.01320884946763722922e+00) (7, -7.65818744596566958194e-01) (0, -3.88692209253759912713e-01) (1, -6.17731223462826384285e-01) (8, -4.95424659679384593591e-01) (6, -4.93231274565637978213e-01) (10, -1.44376083058970361428e+00) (12, 2.86586588288919807965e-01) (4, -1.35599510954988100586e+00) (1, 3.69215938506544771869e+00) (3, 9.63062925382376255889e-01) (2, -1.57080038809081790063e+00) (11, -8.14017679615964551143e-02) (10, -5.73533385475891055449e+00) (12, -6.29982211206810083226e-01) (7, 1.05392903867214844382e+01) (10, -8.54691979412993685372e-01) (4, -8.80458888330629352303e-01) (3, -3.02354440059710105615e+00) (2, -8.81620098569562915536e-01) (5, -4.95440248344603073605e+00) (12, -1.07726031941388078472e-01) (2, -5.54486726606746249679e-01) (11, -4.72288802368777993479e+00) (4, -6.10220005000491783065e-01) (0, 4.29698653769444582906e+00) (5, -4.80208462579387429514e+00) (9, 4.35129728038197693962e+00) (12, 1.84678335127673870497e-01) (1, -3.31480479737211508606e+00) (6, 2.68777781856790864978e+00) (4, 6.75341456976979870319e+00) (8, -4.34547868967475370283e+00) (7, -7.81138186038046633541e+00) (3, 6.95056346955055115444e+00) (12, -3.03627190842981731222e-01) (6, 1.66136378844775545183e+00) (11, -4.63737530363935146482e+00) (3, -3.05037165664567888612e+00) (8, 1.80375248165623314200e+00) (2, 1.24702131790366999020e+00) (1, 4.36609378270952586121e+00) (12, -3.11855149666118602880e-01) (7, 2.84740258797150547210e+00) (5, -3.85162942612623737659e+00) (1, 2.81692549100053080124e+00) (8, 6.97860849337163302586e-01) (6, 7.03863609864296857488e-01) (2, 6.80037337844707656664e-01) (25, -5.54176584382316053667e-02) (18, -3.92072054886333787316e-01) (20, 1.44132729546437493573e-01) (21, 1.65248458033034117953e-01) (22, -3.42403597023910488684e-01) (23, 1.66505716391990188363e-01) (24, 1.02441065796611802119e-01) (25, 5.95110861075250283103e-02) (13, 6.27565040139381080664e-01) (14, -1.54721497041644978632e-01) (15, 4.46157816488643374497e-02) (16, -3.89020497314146243562e-02) (17, -1.19307693465734221405e-01) (19, -4.47545077381087286206e-01) 
